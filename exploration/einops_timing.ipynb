{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "einops_timing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgKnkdx/nfqwnttEeQbjkb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morganmcg1/reformer-fastai/blob/main/exploration/einops_timing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS0ozZ9SUHOe",
        "outputId": "98fa0b32-7c4c-4450-90b5-3b2810d30d85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Nov 11 16:44:03 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3pLmpfGhR7k"
      },
      "source": [
        "!pip install -q einops"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJMO18rhTuMq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd.profiler as profiler\n",
        "from torch.cuda import amp\n",
        "\n",
        "from einops import rearrange"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGNSTYZsZCuG"
      },
      "source": [
        "def time_cuda(f, *args):\n",
        "    f(*args)\n",
        "    torch.cuda.synchronize()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mw-x6L8ZC2g"
      },
      "source": [
        "def dotprod_matmul(q, k, v):\n",
        "    return F.softmax(q@k.transpose(-2,-1), -1) @ v"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YqdPkIkZCzu"
      },
      "source": [
        "def dotprod_einops(q, k, v):\n",
        "    return F.softmax(torch.einsum('bid,bjd->bij', q, k), -1) @ v"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xr0lFOae4Rw"
      },
      "source": [
        "def all_einops(q, k, v):\n",
        "    return torch.einsum('bij,bjd->bid', F.softmax(torch.einsum('bid,bjd->bij', q, k), -1), v)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a60_KirDZCw9"
      },
      "source": [
        "bs = 8\n",
        "sl = 512\n",
        "d = 1024"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-piaxyDZCrN"
      },
      "source": [
        "q, k, v = torch.randn(bs, sl, d*3, device='cuda').chunk(3, -1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ovdGqJDeTUf"
      },
      "source": [
        "assert torch.allclose(dotprod_matmul(q,k,v), dotprod_einops(q,k,v))\n",
        "assert torch.allclose(dotprod_matmul(q,k,v), all_einops(q,k,v))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LhuIAjQdNjo",
        "outputId": "6b9d5d70-5ff4-41f9-b6bd-0303024b2856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "time_cuda(dotprod_matmul, q,k,v)\n",
        "%timeit time_cuda(dotprod_matmul, q,k,v)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 5.46 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF82h39CdfCl",
        "outputId": "6bdf9f18-d1a4-490a-d336-de5c82fdacbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "time_cuda(dotprod_einops, q,k,v)\n",
        "%timeit time_cuda(dotprod_einops, q,k,v)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 4.47 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH2QbEpRfhV0",
        "outputId": "fcc79c41-9f0c-4da8-91f7-7c33b011a4d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "time_cuda(all_einops, q,k,v)\n",
        "%timeit time_cuda(all_einops, q,k,v)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 4.29 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCVhxSfofwxB"
      },
      "source": [
        "## Multihead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Nipqdufudi"
      },
      "source": [
        "def dotprod_matmul(q, k, v):\n",
        "    n_heads = 8\n",
        "    bs, seq_len, d = q.size()\n",
        "    k = k.view(bs, seq_len, n_heads, d//n_heads).transpose(1, 2)\n",
        "    q = q.view(bs, seq_len, n_heads, d//n_heads).transpose(1, 2)\n",
        "    v = v.view(bs, seq_len, n_heads, d//n_heads).transpose(1, 2)\n",
        "    out = F.softmax(q@k.transpose(-2,-1), -1) @ v\n",
        "    return out.transpose(1, 2).contiguous().view(bs, seq_len, d)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvA_p20jfuax"
      },
      "source": [
        "def dotprod_einops(q, k, v):\n",
        "    n_heads = 8\n",
        "    bs, seq_len, d = q.size()\n",
        "    k = k.view(bs, seq_len, n_heads, d//n_heads).transpose(1, 2)\n",
        "    q = q.view(bs, seq_len, n_heads, d//n_heads).transpose(1, 2)\n",
        "    v = v.view(bs, seq_len, n_heads, d//n_heads).transpose(1, 2)\n",
        "    out = torch.einsum('bhij,bhjd->bhid', F.softmax(torch.einsum('bhid,bhjd->bhij', q, k), -1), v)\n",
        "    return out.transpose(1, 2).contiguous().view(bs, seq_len, d)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHF8IQeJfuXx"
      },
      "source": [
        "def all_einops(q, k, v):\n",
        "    n_heads = 8\n",
        "    bs, seq_len, d = q.size()\n",
        "    q = rearrange(q, 'b l (h d) -> b h l d', h=n_heads)\n",
        "    k = rearrange(k, 'b l (h d) -> b h l d', h=n_heads)\n",
        "    v = rearrange(v, 'b l (h d) -> b h l d', h=n_heads)\n",
        "    out = torch.einsum('bhij,bhjd->bhid', F.softmax(torch.einsum('bhid,bhjd->bhij', q, k), -1), v)\n",
        "    return rearrange(out, 'b h n d -> b n (h d)')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIfUpgoLfuS_"
      },
      "source": [
        "assert torch.allclose(dotprod_matmul(q,k,v), dotprod_einops(q,k,v))\n",
        "assert torch.allclose(dotprod_matmul(q,k,v), all_einops(q,k,v))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3f24nUekG86",
        "outputId": "16edf9fc-82fd-4758-dc24-4a4ac6268a06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "time_cuda(dotprod_matmul, q,k,v)\n",
        "%timeit time_cuda(dotprod_matmul, q,k,v)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 7.68 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3Dx3Ou5kNXe",
        "outputId": "e64dab47-02cf-4161-bca4-fcdbbc8fc391",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "time_cuda(dotprod_einops, q,k,v)\n",
        "%timeit time_cuda(dotprod_einops, q,k,v)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 7.61 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S3hLsmzL_ak",
        "outputId": "541f0efa-4d5b-4b58-ce4e-7ca4a4576f26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "time_cuda(all_einops, q,k,v)\n",
        "%timeit time_cuda(all_einops, q,k,v)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 7.75 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqgSKIOhMmuL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}