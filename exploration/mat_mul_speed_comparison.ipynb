{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplication Speed Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.bmm\n",
    "\n",
    "https://discuss.pytorch.org/t/difference-between-matmul-broadcast-and-bmm-on-computational-graph/22674\n",
    "\n",
    ">These two should be equivalent even if they define different computational graphs (potentially doing broadcasting in a different way). That means that, during training, because of floating point precision, they can end up giving noticeably different results as errors are amplified by the training...Both will be correct. You can see changing from one to the other having the same effect as changing the random seed that you set at the beginning of your script: all the numbers you will get will be different but if your model is robust, both should converge to a similar solution in terms of performance.\n",
    "\n",
    "**Example**\n",
    "\n",
    "If input is a (b×n×m) tensor, mat2 is a (b×m×p) tensor, out will be a (b×n×p) tensor.\n",
    "\n",
    "input = torch.randn(10, 3, 4)\n",
    "\n",
    "mat2 = torch.randn(10, 4, 5)\n",
    "\n",
    "res = torch.bmm(input, mat2)\n",
    "\n",
    "res.size()\n",
    "\n",
    "torch.Size([10, 3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 24])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# q = torch.tensor([0,0,0,0,0]\n",
    " \n",
    "tgt_len = src_len = 5\n",
    "bsz = 4\n",
    "n_heads = 2\n",
    "head_dim = 12\n",
    "emb_sz = n_heads * head_dim\n",
    "\n",
    "q = torch.empty(tgt_len, bsz, emb_sz).fill_(2.)\n",
    "k = torch.empty(tgt_len, bsz, emb_sz).fill_(3.)\n",
    "q.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 5, 12]), torch.Size([8, 5, 12]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_mod = q.contiguous().view(tgt_len, bsz * n_heads, head_dim).transpose(0, 1)\n",
    "k_mod = k.contiguous().view(-1, bsz * n_heads, head_dim).transpose(0, 1)\n",
    "q_mod.size(), k_mod.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 5, 5]), torch.Size([8, 5, 5]), torch.Size([8, 5, 5]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output_weights_mod = torch.bmm(q_mod, k_mod.transpose(1, 2))\n",
    "\n",
    "assert list(attn_output_weights_mod.size()) == [bsz * n_heads, tgt_len, src_len]\n",
    "\n",
    "attn_output_weights_mod.size(), (q_mod @ k_mod.transpose(1, 2)).size(), torch.matmul(q_mod, k_mod.transpose(1, 2)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24576, 5, 2000]), torch.Size([24576, 5, 2000]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    " \n",
    "tgt_len = src_len = 5\n",
    "bsz = 1024\n",
    "n_heads = 24\n",
    "emb_sz = 48000\n",
    "head_dim = int(emb_sz / n_heads)\n",
    "# emb_sz = n_heads * head_dim\n",
    "\n",
    "q = torch.empty(tgt_len, bsz, emb_sz).fill_(2.)\n",
    "k = torch.empty(tgt_len, bsz, emb_sz).fill_(3.)\n",
    "\n",
    "q_mod = q.contiguous().view(tgt_len, bsz * n_heads, head_dim).transpose(0, 1)\n",
    "k_mod = k.contiguous().view(-1, bsz * n_heads, head_dim).transpose(0, 1)\n",
    "\n",
    "q_mod.size(), k_mod.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplication Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With View\n",
    "\n",
    "**torch.bmm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 5: 234 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 5\n",
    "attn_output_weights_mod = torch.bmm(q_mod.cuda(), k_mod.transpose(1, 2).cuda())\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@ operator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 5: 245 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 5\n",
    "attn_output_weights_mod = q_mod.cuda() @ k_mod.transpose(1, 2).cuda()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.matmul**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 5: 244 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 5\n",
    "attn_output_weights_mod = torch.matmul(q_mod.cuda(), k_mod.transpose(1, 2).cuda())\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**eimsum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 5: 229 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 5\n",
    "attn_output_weights_mod = torch.einsum('bnm,bmp->bnp', q_mod.cuda(), k_mod.transpose(1, 2).cuda())\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 5, 48000]), torch.Size([1024, 5, 48000]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = q.contiguous().transpose(0, 1)\n",
    "k = k.contiguous().transpose(0, 1)\n",
    "\n",
    "q.size(), k.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.bmm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 5: 233 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 5\n",
    "attn_output_weights_mod = torch.bmm(q.cuda(), k.transpose(1, 2).cuda())\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@ operator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 5: 251 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 5\n",
    "attn_output_weights_mod = q.cuda() @ k.transpose(1, 2).cuda()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.matmul**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 5: 250 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 5\n",
    "attn_output_weights_mod = torch.matmul(q.cuda(), k.transpose(1, 2).cuda())\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**eimsum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 5: 230 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 5\n",
    "attn_output_weights_mod = torch.einsum('bnm,bmp->bnp', q.cuda(), k.transpose(1, 2).cuda())\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Equivalent Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.empty(tgt_len, bsz, emb_sz).fill_(2.)\n",
    "k = torch.empty(tgt_len, bsz, emb_sz).fill_(3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.3728e+09, device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_mod = q.contiguous().view(tgt_len, bsz * n_heads, head_dim).transpose(0, 1)\n",
    "k_mod = k.contiguous().view(-1, bsz * n_heads, head_dim).transpose(0, 1)\n",
    "\n",
    "torch.einsum('bnm,bmp->bnp', q_mod.cuda(), k_mod.transpose(1, 2).cuda()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.3728e+09, device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = q.contiguous().transpose(0, 1)\n",
    "k = k.contiguous().transpose(0, 1)\n",
    "\n",
    "torch.einsum('bnm,bmp->bnp', q.cuda(), k.transpose(1, 2).cuda()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.eisum speed with 4 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1024, 48000])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "tgt_len = src_len = 5\n",
    "bsz = 1024\n",
    "n_heads = 24\n",
    "emb_sz = 48000\n",
    "head_dim = int(emb_sz / n_heads)\n",
    "\n",
    "q = torch.empty(tgt_len, bsz, emb_sz).fill_(2.)\n",
    "k = torch.empty(tgt_len, bsz, emb_sz).fill_(3.)\n",
    "\n",
    "h = n_heads\n",
    "q = torch.empty(tgt_len, bsz, emb_sz).fill_(2.)\n",
    "q.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 24, 1024, 2000])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(q, 'b n (h d) -> b h n d', h = h).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = rearrange(q, 'b n (h d) -> b h n d', h = h)\n",
    "k = rearrange(k, 'b n (h d) -> b h n d', h = h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 5: 270 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 5\n",
    "attn_output_weights_mod = torch.einsum('b h i d, b h j d-> b h i j', q.cuda(), k.cuda())\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
